<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>AI in 2025</title>
</head>
<style>
    body, html {
        margin: 0;
        padding: 0;
        height: 100%;
        border: 0;
    }

    body {
        font-family: Arial, sans-serif;
    }


    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
        display: flex; /* Make it a flex container */
        flex-direction: column; /* Stack items vertically */
        justify-content: center; /* Vertically center the content */
        align-items: center;
    }

    /* Header Styling */
    header {
        padding-top: 40px;
        text-align: center;
        width: 100%;
        justify-content: center;

    }

    /* Article Styling */
    article {
        padding: 20px;
        margin: 20px 0;
        border-radius: 8px;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        text-align: left; /* Align text to the left */
        background-color: #f4f4f4;
        width: 600px;

    }

    #sections {
        display: grid;
        grid-template-columns: repeat(3, auto);
        gap: 3rem;
        justify-content: center;
        padding: 4rem;
    }

    /* Article Header */
    article h1 {
        color: #333;
        font-size: 1.8rem;
        align-items: center;
        justify-content: center;
    }

    /* Paragraph Styling */
    article p {
        line-height: 1.6;
        font-size: 1.1rem;
    }

    img {
        max-width: 600px;
    }
    a {
        display: grid;
        grid-template-columns: repeat(1, auto);
        gap: 1rem;
        justify-content: center;
    }


    /* Footer Styling */
    .footer {
        color: black;
        text-align: center;
        padding: 10px;
        bottom: 0;
        width: 100%;
    }
</style>
<body>
    <section id="sections">

        <h3>Tech</h3>
        <h3>Politics</h3>
        <h3>Culture</h3>
    </section>
    <a href="/Smpl/index.html">Back</a>
    <header>
        <h1>AI in 2025: Where do we go from here?</h1>
    </header>
    <div>

    </div>
    <div class="container">
        <article>
            <img src="/Smpl/images/AI.jpg" alt="" class="thumbnail">
            <p>2024 has undoubtedly been the year of the Multi-modal AI Assistant. Between the launch of the Humane AI Pin, the Rabbit R1, and especially ChatGPT 4o, big tech conglomerates have hedged their bets on the backs of these occasionally friendly-looking everyday helpers. There’s only one problem, they’re not very useful.</p>
            <p>To make a year-long story short, the AI field has had its fair share of hardware and software failures. Reviewers and journalists criticized the new ‘AI Gadgets’, as they have been dubbed. The Humane AI Pin was the first product in this category to be released, and customers could tell. Between the long load times, questionable analog controls, and its limited functionality upon release, the pin critically and perceptually bombed. The Rabbit R1 was the second of these devices to release, and while better than the previous offering, Rabbit failed to convince users that a $200 plastic cube running an Android app was in any way more convenient than your cell phone.</p>
            <p>One bit of silver lining is the reveal and partial release of OpenAI’s ChatGPT 4o (the o is for omnimodal, cool right?). This newest version of the ChatGPT boasted a suite of new features, some of which were also features of the hardware competitors to ChatGPT. You can now speak to 4o using your voice, have a camera recognize your visual context, and respond to external stimuli, and you can experience a faster and more precise search experience through the model. While all these improvements are impressive, we’re still a ways away from the masses adopting such a technology in their everyday workflow. It’s cool that an app on my phone could tell me what’s on my plate through my camera, but in what use case is that ever useful for me? It’s nice that I can ask my Rabbit R1 to read a text message I received, but when it takes the damn thing 5 minutes to find my message, why wouldn’t I just pull out the phone I already need to operate the device? This tech isn’t unimpressive, I’d even go as far as to say that it’s novel stuff, but it hasn’t become more than that. Novel. This stuff gives me no real reason to buy in, and I’m seeing that lots of other people feel this way about AI devices and services in general. </p>
            <p>With the dawn of a new year just ahead at the time of writing, my experience with this technology over the last year has led me to ask one increasingly relevant question. Where do we go from here? Surprisingly, I think the answer to this is extremely simple if you place user experience at the center of your design/use case philosophy. </p>
            <p>You can think of an AI model as a simplified version of the human brain. It is trained on very specific data to recognize patterns and generate a result without human input. If you give me a series of numbers and tell me to add them, I’ll be able to provide you with a result. Now, if you were to change the context and tell me to multiply those same numbers, I could also give you a result. So long as an AI model has enough training in the right contexts, it should be able to recognize the context it’s in and act accordingly. This is the basis behind all the AI products you see on the market today.</p>
            <p>I see many problems with current applications of AI, but the one I’d like to highlight here is the contexts in which these programs are applied. It’s extremely important to recognize that for a technology to be useful, it must be more convenient and/or efficient at a chosen task than the current technology. Take the Humane AI Pin for example, and let's say you’d like to find out the history of a courthouse in your town. You point the pin toward the building and ask, “How long has this courthouse been here?”. After waiting for the pin to connect to its $24-a-month cellular signal (assuming it has enough signal strength), you still have to wait for the pin to query ChatGPT 3.5, retrieve the answer, and relay it to you. This one search involved several more steps than simply taking out your phone and just typing your query on the touch screen you already own. This was the experience of almost everyone who purchased a pin, and the frustration was heard around the entire online tech space. Abysmal experiences like this combined with the fact that the $699 device couldn’t even perform basic tasks like setting timers or ordering DoorDash can be attributed to why Humane processed over $1,000,000 worth of returns for the product, but I don’t even know if the pin would’ve been successful in it’s finished state. Even the pitch for the pin seemed less useful or convenient than a phone, and more expensive in many cases.</p>
            <p>Companies like Humane have grand ambitions for AI Models, and I can admire those ambitions. The truth of the matter, however, is that we’re past the explosive exponential climb for these models. This technology is improving at a slower and slower rate every day, so future visionaries may need to temper their expectations for the scope of their projects. We as a computer science and product development community need to collectively come to grips with the strengths and weaknesses of this technology in its current state. As we’ve seen in 2024, selling on future promises you can’t keep only leads to unsatisfied customers and angry shareholders. I, however, think we can re-center ourselves. We can still make the most of this technology so long as we focus on its strengths.</p>
            <p>Large Language Models are computationally amazing. The amount of information that these programs can process is beyond comprehension. That being said, these LLMs are often used to cover a wide variety of context windows, and often to mixed results. Google has been dealing with consistent misinformation being spread by its Gemini AI Search Summaries, even though Gemini is a notoriously large and power-hungry LLM. OpenAI is no stranger to this either, with ChatGPT consistently spitting out incorrect answers to queries, sometimes to hilarious degrees. LLMs aren’t the solution by themselves, but I believe that we can take some crucial aspects from them. Mainly, I’d like to see a more focused use case for these models than we have now, and I’d like for those focused models to be trained on a wide breadth of information for a select few contexts. That, at least to me, seems like the very best way to end up with a useful technology. At the end of the day, I don’t see these AI features as being enough for a standalone application, and I don’t see them as enough for a physical product, or even Search Engine. I see AI as a fantastic way to augment our already efficient systems to take them to new heights. </p>
            <p>I’m an avid Vergecast listener, and Journalist Nilay Patel in a recent episode compared AI to Bluetooth, putting into words something that I’d been thinking about and ineffectively trying to communicate for almost a year now. This technology is not useful on its own, and it's not at a point where the sole features it provides can make a decent product. Just like there’s no Bluetooth startup claiming that they can revolutionize your life, there shouldn’t be such a thing as an AI Company, at least not one that’s focused on creating products for a casual consumer. I believe that Microsoft and Apple have gone about this type of integration in a better way, while not flawlessly. Don’t get me wrong I have my complaints about Apple Intelligence, and don’t get me started on Copilot, but at least Apple isn’t making an AirTag-sized pin that talks to you and sends your emails for $2,400.</p>
       </article>
    </div>

    <div class="footer">
        <p>&copy; 2025 Smpl. All Rights Reserved.</p>
    </div>

</body>
</html>